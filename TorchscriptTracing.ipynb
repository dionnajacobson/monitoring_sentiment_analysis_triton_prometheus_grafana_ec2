{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25318f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\vearing\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8517eaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model):\n",
    "  \"\"\"Loads model from Hugginface model hub\"\"\"\n",
    "  try:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model, num_labels=2)\n",
    "    return model\n",
    "  except Exception as e:\n",
    "    raise(e)\n",
    "\n",
    "def get_tokenizer(tokenizer):\n",
    "  \"\"\"Loads tokenizer from Hugginface model hub\"\"\"\n",
    "  try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer,padding_side='left')\n",
    "    return tokenizer\n",
    "  except Exception as e:\n",
    "    raise(e)\n",
    "\n",
    "model=get_model('distilbert-base-uncased-finetuned-sst-2-english')\n",
    "tokenizer=get_tokenizer('distilbert-base-uncased-finetuned-sst-2-english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f606785",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=tokenizer.encode('This is the best',return_tensors='pt',max_length=256,truncation=True,padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49407ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyToScript(torch.nn.Module):\n",
    "    def __init__(self,model):\n",
    "        super(PyToScript,self).__init__()\n",
    "        self.model=model\n",
    "    def forward(self,data):\n",
    "        return self.model(data).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8916b589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\vearing\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:214: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  scores = scores.masked_fill(mask, torch.tensor(-float(\"inf\")))  # (bs, n_heads, q_length, k_length)\n"
     ]
    }
   ],
   "source": [
    "pt_model=PyToScript(model).eval()\n",
    "traced=torch.jit.trace(pt_model,inputs)\n",
    "traced.save('model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c26020f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vearing",
   "language": "python",
   "name": "vearing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
